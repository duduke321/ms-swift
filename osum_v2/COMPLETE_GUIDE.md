### 1.1 什么是 GKD LoRA 自蒸馏？

**传统知识蒸馏**：
```
教师模型 (大模型 30B) → 输出分布 A
                          ↓ 蒸馏损失
学生模型 (小模型 7B)  → 输出分布 B
```

**LoRA 自蒸馏（本实现）**：
```
        同一个基础模型 (Qwen3-Omni-30B)
                    │
           ┌────────┴────────┐
           │                 │
      LoRA 禁用          LoRA 启用
      (教师模式)         (学生模式)
           │                 │
      冻结预测          可训练预测
           └────────┬────────┘
                    ↓
                JSD 损失
                    ↓
          只更新 LoRA 参数
```


### 1.3 一图看懂训练流程

```
┌─────────────────────────────────────────────┐
│              一个训练步骤                    │
└─────────────────────────────────────────────┘

Step 1: 决定训练模式
┌──────────────┐
│ random() 生成│
│ 随机数 r     │
└──────┬───────┘
       │
   ┌───┴────────────────┐
   │                    │
r ≤ 0.5              r > 0.5
   ↓                    ↓
┌──────────┐      ┌──────────┐
│On-Policy │      │Off-Policy│
│学生生成  │      │使用原始  │
│新数据    │      │数据集    │
└─────┬────┘      └─────┬────┘
      │                  │
      └──────┬───────────┘
             ↓

Step 2: 双前向传播
┌──────────────────────────────┐
│   共享基础模型 (30B参数)      │
│                              │
│    基础 Transformer 层        │
└──────────┬───────────────────┘
           │
    ┌──────┴──────┐
    │             │
LoRA 禁用     LoRA 启用
(教师)        (学生)
    │             │
    ↓             ↓
┌────────┐  ┌────────┐
│基础输出│  │基础+LoRA│
│ Logits │  │ Logits │
└───┬────┘  └───┬────┘
    │           │
    └─────┬─────┘
          ↓

Step 3: 计算 JSD 损失
┌────────────────────────────┐
│ P_teacher    P_student     │
│     │           │          │
│     └─────┬─────┘          │
│           ↓                │
│    M = 0.5*P_t + 0.5*P_s  │
│     (混合分布)             │
│           │                │
│  ┌────────┴────────┐       │
│  ↓                 ↓       │
│ KL(P_t||M)    KL(P_s||M)  │
│  │                 │       │
│  └────────┬────────┘       │
│           ↓                │
│    JSD = 0.5*KL_t + 0.5*KL_s│
└──────────┬─────────────────┘
           ↓

Step 4: 反向传播（只更新 LoRA）
┌──────────────────────────────┐
│      Loss.backward()         │
│            ↓                 │
│   ┌─────────────────┐        │
│   │ 基础参数 (冻结) │        │
│   │ 梯度 = None     │        │
│   └─────────────────┘        │
│            ↓                 │
│   ┌─────────────────┐        │
│   │ LoRA 参数 ✓     │        │
│   │ 梯度已计算      │        │
│   └────┬────────────┘        │
│        ↓                     │
│   Optimizer.step()           │
│   W_lora -= lr * grad        │
└──────────────────────────────┘
```

---

